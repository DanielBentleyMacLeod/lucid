\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathpartir}
\usepackage{tipa}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\chead{Globally Ordered Type System}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{30pt}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Zt}{$\Z$}

% Create a relational rule
% [#1] - Additional mathpartir arguments
% {#2} - Name of the rule
% {#3} - Premises for the rule
% {#4} - Conclusions for the rule
\newcommand{\relationRule}[4][]{\inferrule*[lab={\sc #2},#1]{#3}{#4}}

\newcommand{\rel}[1]{\ensuremath{\llbracket {#1} \rrbracket}}
\newcommand{\ttt}{\texttt}
\newcommand{\transform}{\rightsquigarrow}
\newcommand{\proj}{\pi}
\newcommand{\ttuple}{(\tau_1, \ldots, \tau_n)}
\newcommand{\etuple}{(e_1,\ldots,e_n)}
\newcommand{\bool}{\mathrm{bool}}
\newcommand{\integer}{\mathrm{int}}
\newcommand{\option}{\mathrm{option}}
\newcommand{\uoption}[1]{(\bool,#1)}
\newcommand{\opt}[1]{\texttt{opt-#1}}
\newcommand{\varOf}[1]{\texttt{varOf}(#1)}

\newcommand{\oktype}{valid}


\begin{document}
	\section*{The System}
	We begin by defining a grammar of "base types". These are the types which are eligible to be stored in global variables. The particular set of base types is not important, but we believe the following ones give a good overview.
	
	\begin{grammar}
		<$T$ (base types)> ::= Unit | Int | Bool | T * T
	\end{grammar}
	
	Everything in the rest of this document is defined with respect to an ordered set $\mathbb{G} = \{g_0, \dots, g_{n-1}\}$ of \emph{global variables}, each of which has an associated base type $T_i$. Our goal is to enforce that $g_0$ is always used before $g_1$, $g_1$ before $g_2$, and so on. For simplicity, we require that each global variable be used; however, we will later relax this restriction by adding subtyping.
	
	In our model, a global variable is not considered \emph{used} until it is actually accessed. Note that this is different from a normal ordered type system, where any appearance of the variable is considered a use. To distinguish appearances from memory accesses, we adopt ref-cell-like syntax for dereferencing or updating global variables. Note that this is different from the user model in actual dpt, where global variables are viewed as simple values. Instead of the ref-cell operators, dpt contains several built-in functions with appropriate type signatures.
	
	The \emph{effects} $\epsilon$ in this system specify which global variables have been used so far. Effects are represented as an integer from $0$ to $n$, where effect $i$ means that all global variables up to but not including $g_i$ have been used so far (that is, we expect to use $g_i$ next).
	
	We will also wish to allow users to define functions which are polymorphic in effect; for example, a function which takes in any global variable, dereferences it, and returns the value. Such a function would have an "effect signature" of something like $\alpha \rightarrow \alpha + 1$. To accommodate this, we will add polymorphic variables and a $+$ constructor to our effect grammar.
	
	Our effects are also intertwined with the language's value types $\tau$, in two ways. First, we have a special $\texttt{ref} (T, \epsilon)$ type for representing the value of a global variable. Second, function types must be altered to include their effect on the global variables. We do so by adding input and output effects to function types as well, using the form $\forall \overline \alpha. (\tau, \epsilon) \rightarrow (\tau, \epsilon)$.
	
	Finally, to facilitate type inference, it will be helpful to place additional information on functions
	in the form of \emph{constraints}. In particular, when we generate a polymorphic function, we will place restrictions on the polymorphic variables; for example, a function which takes and uses two global variables in order may have "effect type" $\forall a,b. (\texttt{ref}(int, a), a) \rightarrow ((\texttt{ref} (int, b), a) \rightarrow (int, b+1), a)$, but also implies that $a < b$. Thus attempting to call this function on the arguments $g_1$ and $g_0$ would fail, but we would not be able to catch this without the constraint that requires $1 < 0$. So we will augment our function types to include lists of constraints that are collected during typechecking of the function, and verified when the function is called.
	
	(Side note: In the constraint-less version, we would typecheck the above function as $\forall a,b. (\texttt{ref}(int, a), a) \rightarrow ((\texttt{ref} (int, a+b+1), a) \rightarrow (int, a+b+2), a)$.
	Note that this uses a more expressive grammar for effects.)
	
	All in all, we have the following grammar of types and effects.
	
	\begin{grammar}
		<$\epsilon$ (effects)> ::= 0 | 1 | \dots | n | $\alpha$ | $\alpha + \Z$
		
		<$c$ (constraint)> ::= $\epsilon \leq \epsilon$
		
		<$cs$ (constraint sets)> ::= sets of constraints
		
		<$\tau$ (types)> ::= T | ref (T, $\epsilon$) | $cs \Rightarrow (\tau, \epsilon) \rightarrow (\tau, \epsilon)$
		
		<$\nu$ (type annotations)> ::= T | ref (T) | $\nu \rightarrow \nu$
		
		<$\sigma$ (schemas)> ::= $\tau$ | $\forall \alpha.\sigma$
	\end{grammar}
	
	Note that we use the convention that when representing effects, $\epsilon$ represents any effect, Latin letters represent only integer effects, and Greek letters represent effect variables. Also note that our constraints reference the effect ordering relation defined below.
	
	Next, we define a simple functional language to use this system on:
	
	\begin{grammar}
		<$x$ (variables)> ::= alphanumeric
		
		<$v$ (values)> ::= () | $\Z$ | True | False | $(v, v)$ | $\texttt{fun}\ (x:\nu) \rightarrow e$ | $g_0$ | \dots | $g_{n-1}$
		
		<$e$ (expressions)> ::= $v$ | $x$ | $e + e$ | $(e,e)$ | fst $e$ | snd $e$ | let $x$ = $e$ in $e$ | if $e$ then $e$ else $e$ | !$e$ | $e := e$ | $e$ $e$
	\end{grammar} 
	
	Note that we treat the global variables as values in their own right in this system.
	
	\clearpage
	\section*{Relations on Effects}
	\subsection*{Effect Equivalence}
	One may notice that our effect grammar allows us to write logically equivalent effects in different ways: for example, $1+1$ or $2$. To avoid this complication, we define an equivalence relation $\equiv$ on effects as follows, using $\oplus$ to represent integer addition:
	
	\begin{mathpar}
		\relationRule{effect-refl}{
			\ 
		}{
			\epsilon \equiv \epsilon
		}
		
		\relationRule{effect-sym}{
			\epsilon_2 \equiv \epsilon_1
		}{
			\epsilon_1 \equiv \epsilon_2
		}
		
		\relationRule{effect-trans}{
			\epsilon_1 \equiv \epsilon_2\\
			\epsilon_2 \equiv \epsilon_3 
		}{
			\epsilon_1 \equiv \epsilon_3
		}
		
		
		\relationRule{int-plus}{
			i \oplus j = k
		}{
			i+j \equiv k
		}
		\\
		\relationRule{plus-comm}{
			\
		}{
			\epsilon_1 + \epsilon_2 \equiv \epsilon_2 + \epsilon_1
		}
		
		\relationRule{plus-assoc}{
			\
		}{
			(\epsilon_1 + \epsilon_2) + \epsilon_3 \equiv \epsilon_1 + (\epsilon_2 + \epsilon_3)
		}
		
		\relationRule{plus-cong}{
			\epsilon_1 \equiv \epsilon_3\\
			\epsilon_2 \equiv \epsilon_4 
		}{
			\epsilon_1 + \epsilon_2 \equiv \epsilon_3 + \epsilon_4
		}
	\end{mathpar}
	
	\subsection*{Effect Substitution}
	In order to define our typing relation, we will need to be able to perform substitution on types to eliminate $\alpha$s. To do so, we define a standard capture-avoiding substitution relation $[\epsilon/\alpha]$, defined below.
	
	\begin{align*}
	\alpha[\epsilon/\alpha] & = \epsilon\\
	\beta[\epsilon/\alpha] & = \beta\ (\mbox{if }\beta \neq \alpha)\\
	i[\epsilon/\alpha] & = i\\
	(\epsilon_1 + \epsilon_2)[\epsilon/\alpha] & = \epsilon_1[\epsilon/\alpha] + \epsilon_2[\epsilon/\alpha]
	\\\hfill\\
	T[\epsilon/\alpha] & = T\\
	(\tau_1 * \tau_2)[\epsilon/\alpha] & = \tau_1[\epsilon/\alpha] * \tau_2[\epsilon/\alpha]\\
	\texttt{ref } (\tau, \epsilon_1)[\epsilon/\alpha] & = \texttt{ref } (\tau[\epsilon/\alpha], \epsilon_1[\epsilon/\alpha])\\
	\left(\forall \overline \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\right)[\epsilon/\alpha] & = \forall \overline \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\\
	\left(\forall \beta.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\right)[\epsilon/\alpha] & = \forall\beta.(\tau_1[\epsilon/\alpha], \epsilon_1[\epsilon/\alpha]) \rightarrow (\tau_2[\epsilon/\alpha], \epsilon_2[\epsilon/\alpha]) \mbox{ (if $\beta \neq \alpha$ and $\beta$ does not appear in $\epsilon$) }
	\end{align*}
	
	We define this to operate on effects and types according to the above rules, and extend it to operate on expressions and environments in the obvious way.
	
	\subsection*{Effect Ordering}
	We define a standard $\leq$ order on effects so we can compare them, using the $\preceq$ symbol to indicate integer less-than-or-equals.
	
	\begin{mathpar}
		\relationRule{leq-trans}{
			\epsilon_1 \leq \epsilon_2\\
			\epsilon_2 \leq \epsilon_3 
		}{
			\epsilon_1 \leq \epsilon_3
		}
		
		\relationRule{leq-equiv}{
			\epsilon_1 \equiv \epsilon_2
		}{
			\epsilon_1 \leq \epsilon_2
		}
		
		\relationRule{leq-int}{
			i \preceq j
		}{
			i \leq j
		}
		
		\relationRule{leq-plus-1}{
			\epsilon_1 \leq \epsilon_3\\
			\epsilon_2 \leq \epsilon_4 
		}{
			\epsilon_1 + \epsilon_2 \leq \epsilon_3 + \epsilon_4
		}
		
		\relationRule{leq-plus-2}{
			\
		}{
			\epsilon_1 \leq \epsilon_1 + \epsilon_2
		}
	\end{mathpar}
	
	\clearpage
	
	The short version: Algorithm W, except with constraints. We instantiate all quantified type variables (QVars) with new free type variables (TVars) whenever we typecheck a variable. When we typecheck a deref/update of ref $\epsilon_2$ starting in state $\epsilon_1$, we add a constraint that $\epsilon_1 \leq \epsilon_2$. When we typecheck a function call $f\ x$, we unify the input of $f$ with $x$ as usual, then add all constraints on $f$ after unification to our constraint set (optionally, we check if it's SAT first).
	
	Essentially, all we're doing is taking every place where a user-provided effect was originally provided, replacing it with a free type variable, and doing instantiation. In hindsight, this is pretty obvious.
	
	\section*{The Typing Relation}
	Type inference in this system simultaneously reasons about effects and regular types. As a result, the typing relation has an extra input and output, representing the state of the global variables before and after the expression, respectively. 
	
	Furthermore, we keep track of a list of constraints about all our effects. We check satisfiability of these constraints whenever we generalize a function type. One could also imagine doing this check at various other points (such as whenever we add a constraint), but the choice of whether or not to do so is an implementation decision that affects how errors are reported, not a correctness decisions.
	
	Finally, we also return a substitution $S$ of the form $[\alpha_1 \mapsto \tau_1, \dots, \alpha_n \mapsto \tau_n]$. We denote the composition of $S_1$ and $S_2$ (applied in that order) by $S_2S_1$, and the application of the substitution $S$ to a schema or environment by $S\sigma$ and $S\Gamma$. We denote the empty substitution by $[]$.
	
	Our typing relation will thus have the form $\Gamma, \epsilon \vdash e\ \colon \tau, \epsilon, cs, S$. As usual, $\Gamma$ represents our current collection of bound variables; we treat it as a map from variables to schemas. Our goal is that our program $p$ satisfies $\emptyset, 0 \vdash p\ \colon \tau, i, \emptyset$ for some $\tau, i$.
	
	When writing rules, we use the convention that the metavariable $x$ matches all \emph{non-global} variables. We will always denote global variables using symbols of the form $g_i$. For the rest of these rules we will treat effects as being equal if they are equivalent.
	
	We now define some auxiliary functions. The function $\texttt{inst} : \sigma \rightarrow \tau$ instantiates all quantified variables in $\sigma$ with \emph{fresh} type variables. The function $\texttt{mgu}(\tau_1, \tau_2)$ returns the most general unifier (a substitution) which turns $\tau_1$ and $\tau_2$ into the same thing, or fails (aborting the typechecking) if no such unifier exists. We define $\texttt{Gen}(\Gamma, \tau)$ which generalizes $\tau$ with respect to $\Gamma$; that is, $\texttt{Gen}(\Gamma, \tau) = \forall \alpha_1...\alpha_k.\tau$, where $\alpha_1$ through $\alpha_k$ are all the free type variables in $\tau$ that do not appear free in $\Gamma$. We define $\texttt{annot}(\nu)$ to add fresh type vars to refs and functions that appear in $\nu$, and add empty constraint sets to the functions.
	
	\begin{mathpar}
		\relationRule{int}{
			n \in \Z
		}{
			\Gamma, \epsilon \vdash n\ \colon \texttt{Int}, \epsilon, \emptyset, []
		}
		
		\relationRule{true}{
			\ 
		}{
			\Gamma, \epsilon \vdash \texttt{True}\ \colon \texttt{Bool}, \epsilon, \emptyset, []
		}
		
		\relationRule{false}{
			\ 
		}{
			\Gamma, \epsilon \vdash \texttt{False}\ \colon \texttt{Bool}, \epsilon, \emptyset, []
		}
		
		\relationRule{Unit}{
			\ 
		}{
			\Gamma, \epsilon \vdash ()\ \colon \texttt{Unit}, \epsilon, \emptyset, []
		}
		
		\relationRule{global variable}{
			\
		}{
			\Gamma, \epsilon \vdash g_i\ \colon \texttt{ref}(T_i, i), \epsilon, \emptyset, []
		}
	\end{mathpar}
	
	Now we can write rules for non-value expressions:
	
	\begin{mathpar}
		\relationRule{local variable}{
			\Gamma[x] = \sigma
		}{
			\Gamma, \epsilon \vdash x\ \colon \texttt{inst}(\sigma), \epsilon, []
		}
		
		\relationRule{plus}{
			\Gamma, \epsilon \vdash e_1\ \colon \texttt{Int}, \epsilon_1, cs_1, S_1\\
			S_1\Gamma, \epsilon_1 \vdash e_2\ \colon \texttt{Int}, \epsilon_2, cs_2, S_2
		}{
			\Gamma, \epsilon \vdash e_1 + e_2\ \colon \texttt{Int}, \epsilon_2, S_2cs_1 \cup cs_2, S_2S_1
		}
		
		\relationRule{pair}{
			\Gamma, \epsilon \vdash e_1\ \colon \tau_1, \epsilon_1, cs_1, S_1\\
			S_1\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2, cs_2, S_2
		}{
			\Gamma, \epsilon \vdash (e_1, e_2)\ \colon S_2\tau_1 * \tau_2, \epsilon_2, S_2cs_1 \cup cs_2, S_2S_1
		}
		
		\relationRule{fst}{
			\Gamma, \epsilon \vdash e\ \colon \tau_1 * \tau_2, \epsilon_1, cs_1, S_1
		}{
			\Gamma, \epsilon \vdash \texttt{fst } e\ \colon \tau_1, \epsilon_1, cs_1, S_1
		}
		
		\relationRule{snd}{
			\Gamma, \epsilon \vdash e\ \colon \tau_1 * \tau_2, \epsilon_1, cs_1, S_1\\
		}{
			\Gamma, \epsilon \vdash \texttt{snd } e\ \colon \tau_2, \epsilon_1, cs_1, S_1
		}
		
		\relationRule{let}{
			\Gamma, \epsilon \vdash e_1\ \colon \tau_1, \epsilon_1, cs_1, S_1\\
			S_1\Gamma[x := \texttt{Gen}(S_1\Gamma, \tau_1)], \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2, cs_2, S_2
		}{
			\Gamma, \epsilon \vdash \texttt{let } x = e_1 \texttt{ in } e_2\ \colon \tau_2, \epsilon_2, S_2cs_1 \cup cs_2, S_2S_1
		}
		
		\relationRule{if}{
			\Gamma, \epsilon \vdash e_1\ \colon \texttt{Bool}, \epsilon_1, cs_1, S_1\\
			S_1\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2, cs_2, S_2\\
			S_2S_1\Gamma, S_2\epsilon_1 \vdash e_3\ \colon \tau_3, \epsilon_3, cs_3, S_3\\
			S_4 = \texttt{mgu}(S_3\tau_2, \tau_3)\\
			S_5 = \texttt{mgu}(S_4S_3\epsilon_2, S_4\epsilon_3)\\
		}{
			\Gamma, \epsilon \vdash \texttt{if } e_1 \texttt{ then } e_2 \texttt{ else } e_3\ \colon \tau, \epsilon_3, S_5S_4S_3S_2cs_1 \cup S_5S_4S_3cs_2 \cup S_5S_4cs_3, S_5S_4S_3S_2S_1
		}
	\end{mathpar}
	
	Now let's finally write some rules that actually change $\epsilon$.
	
	\begin{mathpar}
		\relationRule{deref}{
			\Gamma, \epsilon \vdash e\ \colon \texttt{ref} (T, \epsilon_2), \epsilon_1, cs_1, S_1\\
		}{
			\Gamma, \epsilon \vdash\ !e\ \colon T, \epsilon_2+1, cs_1 \cup \{\epsilon_1 \leq \epsilon_2\}, S_1
		}
		
		\relationRule{update}{
			\Gamma, \epsilon \vdash e_1\ \colon T, \epsilon_1, cs_1, S_1\\
			S_1\Gamma, \epsilon_1 \vdash e_2\ \colon \texttt{ref}(T, \epsilon_3), \epsilon_2, cs_2, S_2
		}{
			\Gamma, \epsilon \vdash e_2 := e_1\ \colon \texttt{Unit}, \epsilon_3+1, S_2cs_1 \cup cs_2 \cup \{\epsilon_2 \leq \epsilon_3\}, S_2S_1
		}
	\end{mathpar}
	
	And finally, the function rules: 
	\begin{mathpar}
		\relationRule{abs}{
			\tau_x = \texttt{annot}(\nu)\\
			\Gamma[x := \tau_x], \alpha \vdash e\ \colon \tau, \epsilon_1, cs, S\\
			\alpha \mbox{ fresh}\\
			cs \mbox{ is SAT}
		}{
			\Gamma, \epsilon \vdash \texttt{fun } (x : \nu) \rightarrow e\ \colon cs \Rightarrow (S\tau_x, S\alpha) \rightarrow (\tau, \epsilon_1), S\epsilon, cs, S
		}
		
		\relationRule{app}{
			\Gamma, \epsilon \vdash e_1 \colon cs_f \Rightarrow (\tau_{in}, \epsilon_{in}) \rightarrow (\tau_{out}, \epsilon_{out}), \epsilon_1, cs_1, S_1\\
			S_1\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_{in}', \epsilon_{in}', cs_2, S_2\\
			S_3 = \texttt{mgu}(S_2\tau_{in}, \tau_{in}')\\
			S_4 = \texttt{mgu}(S_3S_2\epsilon_{in}, S_3\epsilon_{in}')\\
			S_4S_3S_2cs_f \mbox{ is SAT}
		}{
			\Gamma, \epsilon \vdash e_1\ e_2\ \colon S_4S_3S_2\tau_{out}, S_4S_3S_2\epsilon_{out}, S_4S_3S_2cs_1 \cup S_4S_3cs_2 \cup S_4S_3S_2cs_f, S_4S_3S_2S_1
		}
	\end{mathpar}

Question: do we need something like an interpolant? It would be very nice to ensure that the constraints on a function only refer to variables that it quantifies. And free variables in the environment when it's defined. I think this happens automatically though.
	
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End: 
\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{syntax}
\usepackage{stmaryrd}
\usepackage{mathpartir}
\usepackage{tipa}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\chead{Globally Ordered Type System}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{30pt}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Zt}{$\Z$}

% Create a relational rule
% [#1] - Additional mathpartir arguments
% {#2} - Name of the rule
% {#3} - Premises for the rule
% {#4} - Conclusions for the rule
\newcommand{\relationRule}[4][]{\inferrule*[lab={\sc #2},#1]{#3}{#4}}

\newcommand{\rel}[1]{\ensuremath{\llbracket {#1} \rrbracket}}
\newcommand{\ttt}{\texttt}
\newcommand{\transform}{\rightsquigarrow}
\newcommand{\proj}{\pi}
\newcommand{\ttuple}{(\tau_1, \ldots, \tau_n)}
\newcommand{\etuple}{(e_1,\ldots,e_n)}
\newcommand{\bool}{\mathrm{bool}}
\newcommand{\integer}{\mathrm{int}}
\newcommand{\option}{\mathrm{option}}
\newcommand{\uoption}[1]{(\bool,#1)}
\newcommand{\opt}[1]{\texttt{opt-#1}}
\newcommand{\varOf}[1]{\texttt{varOf}(#1)}

\newcommand{\oktype}{valid}


\begin{document}
\section*{The System}
We begin by defining a grammar of "base types". These are the types which are eligible to be stored in global variables. The particular set of base types is not important, but we believe the following ones give a good overview.

\begin{grammar}
	<$T$ (base types)> ::= Unit | Int | Bool | T * T
\end{grammar}

Everything in the rest of this document is defined with respect to an ordered set $\mathbb{G} = \{g_1, \dots, g_n\}$ of \emph{global variables}, each of which has an associated base type $T_i$. Our goal is to enforce that $g_1$ is always used before $g_2$, $g_2$ before $g_3$, and so on. For simplicity, we require that each global variable be used; however, we will later relax this restriction by adding subtyping.

In our model, a global variable is considered \emph{used} until it is actually accessed. Note that this is different from a normal ordered type system, where any appearance of the variable is considered a use. To distinguish appearances from memory accesses, we adopt ref-cell-like syntax for dereferencing or updating global variables. Note that this is different from the user model in actual dpt, where global variables are viewed as simple values. Instead of the ref-cell operators, dpt contains several built-in functions with appropriate type signatures.

The \emph{effects} $\epsilon$ in this system specify which global variables have been used so far. Effects are represented as an integer from $1$ to $n+1$, where effect $i$ means that all global variables up to but not including $g_i$ have been used so far (that is, we expect to use $g_i$ next).

We will also wish to allow users to define functions which are polymorphic in effect; for example, a function which takes in any global variable, dereferences it, and returns the value. Such a function would have an "effect signature" of something like $\alpha \rightarrow \alpha + 1$. To accommodate this, we will add polymorphic variables and a $+$ operation to our effect grammar.

Our effects are also intertwined with the language's value types $\tau$, in two ways. First, we have a special $\texttt{ref} (T, \epsilon)$ type for representing the value of a global variable. Second, function types must be altered to include their effect on the global variables. We do so by adding input and output effects to function types as well, using the form $(\tau, \epsilon) \rightarrow (\tau, \epsilon)$.

All in all, we have the following grammar of types and effects.

\begin{grammar}
	<$\epsilon$ (effects)> ::= 1 | 2 | \dots | n + 1 | $\alpha$ | $\epsilon + \epsilon$
	
	<$\tau$ (types)> ::= T | $\tau * \tau$ | ref ($\tau, \epsilon$) | $\forall \alpha.(\tau, \epsilon) \rightarrow (\tau, \epsilon)$
\end{grammar}

Note that we use the convention that when representing effects, $\epsilon$ represents any effect, Latin letters represent only integer effects, and Greek letters represent effect variables.

Next, we define a simple functional language to use this system on:

\begin{grammar}
	<$x$ (variables)> ::= alphanumeric
	
	<$\Gamma$ (environments)> ::= Maps from variables to values
	
	<$v$ (values)> ::= () | $\Z$ | True | False | $(v, v)$ | \textless$\Gamma, \alpha, (x : \tau, \epsilon), e $\textgreater\ | $g_1$ | \dots | $g_n$
	
	<$e$ (expressions)> ::= $v$ | $x$ | $e + e$ | $(e,e)$ | fst $e$ | snd $e$ | let $x$ = $e$ in $e$ | if $e$ then $e$ else $e$ | !$e$ | $e := e$
	\alt $\texttt{fun}\ [\alpha]\ (x:\tau, \epsilon)  \rightarrow e$ | $e[\epsilon]$ $e$
\end{grammar} 

Note that we treat the global variables as values in their own right in this system.

The $\texttt{fun}\ [\alpha]$ syntax defines an effect-polymorphic function whose effects may use the universally quantified effect variable $\alpha$. The $e[\epsilon]$ $e$ syntax applies an effect-polymorphic function, instantiating $\alpha$ with $\epsilon$.

\clearpage
\section*{Typing Programs}
\subsection*{Effect Equivalence}
One may notice that our effect grammar allows us to write logically equivalent effects in different ways: for example, $1+1$ or $2$. To avoid this complication, we define an equivalence relation $\equiv$ on effects as follows, using $\oplus$ to represent integer addition:

\begin{mathpar}
	\relationRule{effect-refl}{
		\ 
	}{
		\epsilon \equiv \epsilon
	}

	\relationRule{effect-sym}{
		\epsilon_2 \equiv \epsilon_1
	}{
		\epsilon_1 \equiv \epsilon_2
	}

	\relationRule{effect-trans}{
		\epsilon_1 \equiv \epsilon_2\\
		\epsilon_2 \equiv \epsilon_3 
	}{
		\epsilon_1 \equiv \epsilon_3
	}

	
	\relationRule{int-plus}{
		i \oplus j = k
	}{
		i+j \equiv k
	}
\\
	\relationRule{plus-comm}{
		\
	}{
		\epsilon_1 + \epsilon_2 \equiv \epsilon_2 + \epsilon_1
	}

	\relationRule{plus-assoc}{
		\
	}{
		(\epsilon_1 + \epsilon_2) + \epsilon_3 \equiv \epsilon_1 + (\epsilon_2 + \epsilon_3)
	}

	\relationRule{plus-cong}{
		\epsilon_1 \equiv \epsilon_3\\
		\epsilon_2 \equiv \epsilon_4 
	}{
		\epsilon_1 + \epsilon_2 \equiv \epsilon_3 + \epsilon_4
	}
\end{mathpar}

\subsection*{Effect Substitution}
In order to define our typing relation, we will need to be able to perform substitution on types to eliminate $\alpha$s. To do so, we define a standard capture-avoiding substitution relation $[\epsilon/\alpha]$, defined below.

\begin{align*}
	\alpha[\epsilon/\alpha] & = \epsilon\\
	\beta[\epsilon/\alpha] & = \beta\ (\mbox{if }\beta \neq \alpha)\\
	i[\epsilon/\alpha] & = i\\
	(\epsilon_1 + \epsilon_2)[\epsilon/\alpha] & = \epsilon_1[\epsilon/\alpha] + \epsilon_2[\epsilon/\alpha]
\\\hfill\\
	T[\epsilon/\alpha] & = T\\
	(\tau_1 * \tau_2)[\epsilon/\alpha] & = \tau_1[\epsilon/\alpha] * \tau_2[\epsilon/\alpha]\\
	\texttt{ref } (\tau, \epsilon_1)[\epsilon/\alpha] & = \texttt{ref } (\tau[\epsilon/\alpha], \epsilon_1[\epsilon/\alpha])\\
	\left(\forall \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\right)[\epsilon/\alpha] & = \forall \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\\
	\left(\forall \beta.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)\right)[\epsilon/\alpha] & = \forall \beta.(\tau_1[\epsilon/\alpha], \epsilon_1[\epsilon/\alpha]) \rightarrow (\tau_2[\epsilon/\alpha], \epsilon_2[\epsilon/\alpha])\ (\mbox{if }\beta \neq \alpha \mbox{ and } \beta \mbox{ does not appear in } \epsilon)
\end{align*}

\subsection*{Effect Ordering}
We define a standard $\leq$ order on effects so we can compare them, using the $\preceq$ symbol to indicate integer less-than-or-equals.

\begin{mathpar}
	\relationRule{leq-refl}{
		\
	}{
		\epsilon \leq \epsilon
	}

	\relationRule{leq-trans}{
		\epsilon_1 \leq \epsilon_2\\
		\epsilon_2 \leq \epsilon_3 
	}{
		\epsilon_1 \leq \epsilon_3
	}

	\relationRule{leq-equiv}{
		\epsilon_1 \equiv \epsilon_2
	}{
		\epsilon_1 \leq \epsilon_2
	}

	\relationRule{leq-int}{
		i \preceq j
	}{
		i \leq j
	}

	\relationRule{leq-plus-1}{
		\epsilon_1 \leq \epsilon_3\\
		\epsilon_2 \leq \epsilon_4 
	}{
		\epsilon_1 + \epsilon_2 \leq \epsilon_3 + \epsilon_4
	}

	\relationRule{leq-plus-2}{
		\
	}{
		\epsilon_1 \leq \epsilon_1 + \epsilon_2
	}
\end{mathpar}

\section*{The Typing Relation}
Type inference in this system simultaneously reasons about effects and regular types. As a result, the typing relation has an extra input and output, representing the state of the global variables before and after the expression, respectively.

Our typing relation will thus have the form $\Gamma, \epsilon \vdash e\ \colon \tau, \epsilon$. As usual, $\Gamma$ represents our current collection of bound variables; we treat it as a set. Our goal is that our program $p$ satisfies $\emptyset, 1 \vdash p\ \colon \tau, n+1$ for some $\tau$.

When writing rules, we use the convention that the metavariable $x$ matches all \emph{non-global} variables. We will always denote global variables using symbols of the form $g_i$. For the rest of these rules we will treat effects as being equal if they are equivalent.

Definition: a type $\tau$ is said to be \emph{\oktype} if all sub-parts of $\tau$ are \oktype, and if $\tau = \forall \alpha.(\tau_1, \epsilon_{in}) \rightarrow (\tau_2, \epsilon_{out})$ implies $\epsilon_{in} \leq \epsilon_{out}$.

For a given value environment $\Gamma$, we define $\Gamma_\tau$ to be any typing environment with the same elements as $\Gamma$ and such that $\forall y \in \Gamma. \emptyset, 1 \vdash \Gamma[y]\ \colon \Gamma_\tau[y], 1$.

$\texttt{fun } [\alpha, \beta] (f : (\forall \gamma. (\tau, \alpha) \rightarrow (\tau', \beta)) = f\ ...$

\begin{mathpar}
	\relationRule{int}{
		n \in \Z
	}{
		\Gamma, \epsilon \vdash n\ \colon \texttt{Int}, \epsilon
	}

	\relationRule{true}{
		\ 
	}{
		\Gamma, \epsilon \vdash \texttt{True}\ \colon \texttt{Bool}, \epsilon
	}

	\relationRule{false}{
		\ 
	}{
		\Gamma, \epsilon \vdash \texttt{False}\ \colon \texttt{Bool}, \epsilon
	}

	\relationRule{Unit}{
		\ 
	}{
		\Gamma, \epsilon \vdash ()\ \colon \texttt{Unit}, \epsilon
	}

	\relationRule{global variable}{
		\
	}{
		\Gamma, \epsilon \vdash g_i\ \colon \texttt{ref}(T_i, i), \epsilon
	}

	\relationRule{Closure}{
		\tau\mbox{ is \oktype}\\
		\Gamma_\tau[x := \tau], \epsilon_f \vdash e\ \colon \tau_1, \epsilon_1
	}{
		\Gamma_0, \epsilon \vdash\ <\Gamma, \alpha, (x : \tau, \epsilon_f), e >\ \colon \forall \alpha.(\tau, \epsilon_f) \rightarrow (\tau_1, \epsilon_1), \epsilon
	}
\end{mathpar}

Now we can write rules for non-value expressions:

\begin{mathpar}
	\relationRule{local variable}{
		\Gamma[x] = \tau
	}{
		\Gamma, \epsilon \vdash x\ \colon \tau, \epsilon
	}

	\relationRule{plus}{
		\Gamma, \epsilon \vdash e_1\ \colon \texttt{Int}, \epsilon_1\\
		\Gamma, \epsilon_1 \vdash e_2\ \colon \texttt{Int}, \epsilon_2
	}{
		\Gamma, \epsilon \vdash e_1 + e_2\ \colon \texttt{Int}, \epsilon_2
	}
	
	\relationRule{pair}{
		\Gamma, \epsilon \vdash e_1\ \colon \tau_1, \epsilon_1\\
		\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2
	}{
		\Gamma, \epsilon \vdash (e_1, e_2)\ \colon \tau_1 * \tau_2, \epsilon_2
	}

	\relationRule{fst}{
		\Gamma, \epsilon \vdash e\ \colon \tau_1 * \tau_2, \epsilon_1\\
	}{
		\Gamma, \epsilon \vdash \texttt{fst } e\ \colon \tau_1, \epsilon_1
	}

	\relationRule{snd}{
		\Gamma, \epsilon \vdash e\ \colon \tau_1 * \tau_2, \epsilon_1\\
	}{
		\Gamma, \epsilon \vdash \texttt{snd } e\ \colon \tau_2, \epsilon_1
	}

	\relationRule{let}{
		\Gamma, \epsilon \vdash e_1\ \colon \tau_1, \epsilon_1\\
		\Gamma[x := \tau_1], \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2
	}{
		\Gamma, \epsilon \vdash \texttt{let } x = e_1 \texttt{ in } e_2\ \colon \tau_2, \epsilon_2
	}

	\relationRule{if}{
		\Gamma, \epsilon \vdash e_1\ \colon \texttt{Bool}, \epsilon_1\\
		\Gamma, \epsilon_1 \vdash e_2\ \colon \tau, \epsilon_2\\
		\Gamma, \epsilon_1 \vdash e_3\ \colon \tau, \epsilon_2
	}{
		\Gamma, \epsilon \vdash \texttt{if } e_1 \texttt{ then } e_2 \texttt{ else } e_3\ \colon \tau, \epsilon_2
	}
\end{mathpar}

Now let's finally write some rules that actually change $\epsilon$.

\begin{mathpar}
	\relationRule{deref}{
		\Gamma, \epsilon \vdash e\ \colon \texttt{ref}(\tau, \epsilon_1), \epsilon_1
	}{
		\Gamma, \epsilon \vdash !e\ \colon \tau, \epsilon_1+1
	}

\relationRule{update}{
	\Gamma, \epsilon \vdash e_1\ \colon \tau, \epsilon_1\\
	\Gamma, \epsilon_1 \vdash e_2\ \colon \texttt{ref}(\tau, \epsilon_2), \epsilon_2
}{
	\Gamma, \epsilon \vdash e_2 := e_1\ \colon \texttt{Unit}, \epsilon_2+1
}
\end{mathpar}

And finally, the function rules: 
\begin{mathpar}
	\relationRule{abs}{
		\tau\mbox{ is \oktype}\\
		\Gamma[x := \tau], \epsilon_f \vdash e\ \colon \tau_1, \epsilon_1
	}{
		\Gamma, \epsilon \vdash \texttt{fun } [\alpha] (x : \tau, \epsilon_f) \rightarrow e\ \colon \forall \alpha.(\tau, \epsilon_f) \rightarrow (\tau_1, \epsilon_1), \epsilon
	}
	
	\relationRule{app}{
		\Gamma, \epsilon \vdash e_1\ \colon \forall \alpha.(\tau_2, \epsilon_2) \rightarrow (\tau', \epsilon'), \epsilon_1\\
		\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2[\epsilon_\alpha/\alpha], \epsilon_2[\epsilon_\alpha/\alpha]\\
	}{
		\Gamma, \epsilon \vdash e_1[\epsilon_\alpha]\ e_2\ \colon \tau'[\epsilon_\alpha/\alpha], \epsilon'[\epsilon_\alpha/\alpha]
	}
\end{mathpar}

\subsection*{Skipping Variables}
In practice, the requirement that we \emph{must} use each global variable more restrictive than we would like. We would like to programs in which some global variables are skipped. We do this by adding a subtyping relation on effects and types.

\begin{mathpar}
	\relationRule{sub-refl}{
		\ 
	}{
		\tau <: \tau
	}

	\relationRule{sub-pair}{
		\tau_1 <: \tau_3\\
		\tau_2 <: \tau_4\\
	}{
		(\tau_1, \tau_2) <: (\tau_3, \tau_4)
	}

	\relationRule{sub-function}{
		\tau_1' <: \tau_1\\
		\tau_2 <: \tau_2'\\
		\epsilon_1' \leq \epsilon_1 \leq \epsilon_2 \leq \epsilon_2'
	}{
		\forall \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2) <: \forall \alpha.(\tau_1', \epsilon_1') \rightarrow (\tau_2', \epsilon_2')
	}
\end{mathpar}

Finally, we augment our typing relation with the single rule
\begin{mathpar}
	\relationRule{subtyping}{
		\tau_1 <: \tau_2\\
		\epsilon_1 \leq \epsilon_2\\
		\Gamma, \epsilon \vdash e\ \colon \tau_1, \epsilon_1
	}{
		\Gamma, \epsilon \vdash e\ \colon \tau_2, \epsilon_2
	}
\end{mathpar}

Note that we only really have two uses for this new typing rule: replacing functions, and incrementing the effect.

\section*{Properties of the Typing Relation}

\subsection*{Transitivity of subtyping}
Theorem: If $\tau_1 <: \tau_2$ and $\tau_2 <: \tau_3$ then $\tau_1 <: \tau_3$.
\\

\noindent Proof: Straightforward structural induction on the proof that $\tau_1 <: \tau_2$, using inversion on the proof that $\tau_2 <: \tau_3$.

\subsection*{A shorthand for values}
Definition: We will write $v : \tau$ as shorthand for $\forall\ \Gamma, \epsilon.\ \Gamma, \epsilon \vdash v\ \colon \tau, \epsilon$.
\\

\noindent Theorem: If $\Gamma, \epsilon \vdash v\ \colon \tau, \epsilon'$ then $v : \tau$.
\\

\noindent Proof: Straightforward structural induction on the typing derivation. If we used a value rule we may immediately reapply it. In the PAIR and SUBTYPING cases the result follows quickly by induction.

\subsection*{Monotonicity}
In our later proofs, we will need to use a monotonicity property stating that the effect only ever increases when we make typing judgements. Before we can prove that, though, we need some lemmas about substitution and the \oktype\ property.
\\

\noindent Lemma M-1: For all $\epsilon, \epsilon_1, \epsilon_2, \alpha$, if $\epsilon_1 \equiv \epsilon_2$, then $\epsilon_1[\epsilon/\alpha] \equiv \epsilon_2[\epsilon/\alpha]$

\noindent Proof: Straightforward structural induction on the proof that $\epsilon_1 \equiv \epsilon_2$.
\\

\noindent Lemma M-2: For all $\epsilon, \epsilon_1, \epsilon_2, \alpha$, if $\epsilon_1 \leq \epsilon_2$, then $\epsilon_1[\epsilon/\alpha] \leq \epsilon_2[\epsilon/\alpha]$

\noindent Proof: Straightforward structural induction on the proof that $\epsilon_1 \leq \epsilon_2$, using lemma M-1 in the \texttt{leq-equiv} case.
\\

\noindent Lemma M-3: if $\tau$ is \oktype, then for all $\epsilon, \alpha$, $\tau[\epsilon/\alpha]$ is also \oktype.
 
\noindent Proof: Straightforward structural induction on $\tau$, using lemma M-2 in the function case.
\\

\noindent Lemma M-4: if $\tau_1 <: \tau_2$, then $\tau_1$ is \oktype\ if and only if $\tau_2$ is \oktype.

\noindent Proof: Straightforward structural induction on the proof that $\tau_1 <: \tau_2$.
\\

\noindent Theorem: If $\Gamma, \epsilon_1 \vdash e\ \colon \tau, \epsilon_2$ and all elements of $\Gamma$ are \oktype\, then $\tau$ is \oktype\ and $\epsilon_1 \leq \epsilon_2$.

\noindent We don't actually care about $\tau$ being \oktype\ (although it's a nice result), but we need it during the proof
\\

\noindent Proof of Theorem: Straightforward induction on the typing derivation. The interesting bits are:
\begin{itemize}
	\item In the CLOSURE rule, we show inductively that all elements of $\Gamma_\tau$ are \oktype.
	\item In the LOCAL VARIABLE rule, we use the fact that all elements of $\Gamma$ are \oktype.
	\item In the GLOBAL VARIABLE rule, use the fact that all base types are valid.
	\item In the ABS case we need to do a little work to show that the output is \oktype.
	\item In the APP case we use lemmas M-2 and M-3.
	\item In the SUBTYPING case we use lemma M-4.
\end{itemize}

\subsection*{Canonical Forms}
Lemma C-1: If $\tau_1 <: \tau_2$, then:
\begin{itemize}
	\item If either $\tau_1$ or $\tau_2$ is a base type or $\texttt{ref}$ type then $\tau_1 = \tau_2$
	\item If either $\tau_1$ or $\tau_2$ is a pair type, then $\tau_1 = (\tau_a, \tau_b)$ and $\tau_2 = (\tau_c, \tau_d)$ where $\tau_a <: \tau_c$ and $\tau_b <: \tau_d$.
	\item If either $\tau_1$ or $\tau_2$ is a function type, then $\tau_1 = \forall \alpha. (\tau_a, \epsilon_a) \rightarrow (\tau_b, \epsilon_b)$ and $\tau_2 = \forall \alpha. (\tau_c, \epsilon_c) \rightarrow (\tau_d, \epsilon_d)$ where $\tau_c <: \tau_a$, $\tau_b <: \tau_d$, and $\epsilon_a \leq \epsilon_c \leq \epsilon_b \leq \epsilon_d$.
\end{itemize} 

\noindent Proof: Inversion of the typing relation.
\\

\noindent Theorem: For all values $v$, if $v\ \colon \tau$ then
\begin{itemize}
	\item If $\tau = \texttt{Int}$ then $v \in \Z$
	\item If $\tau = \texttt{Bool}$ then $v = \texttt{True}$ or $v = \texttt{False}$
	\item If $\tau = \texttt{Unit}$ then $v = ()$
	\item If $\tau = \tau_1 * \tau_2$ then $v = (v_1, v_2)$ where $v_1 : \tau_1$ and $v_2 : \tau_2$.
	\item If $\tau = \texttt{ref} (\tau_1, \epsilon)$ then $\epsilon = i \in \Z$, $v = g_i$ and $\tau_1 = T_i$.
	\item If $\tau = \forall \alpha.(\tau_1, \epsilon_1) \rightarrow (\tau_2, \epsilon_2)$ then $v =\ <\Gamma, \alpha, (x : \tau', \epsilon'), e>$ for some $\Gamma, \tau', \epsilon', e$.
\end{itemize}

\noindent Proof: Case analysis on the proof that $v$ has type $\tau$ for some arbitrary $\Gamma, \epsilon$. Each $\tau$ has only two (or three, for booleans) that apply to a value and produce it: the base rules, and the subtyping rule. In the subtyping cases, we use Lemma C-1. In the pair case, we use induction, and in the case where $\tau$ is a pair type and the subtyping rule was used, we Lemma C-1 twice in addition to induction.

\subsection*{The Substitution Lemma}

\noindent Definition: If $\Gamma$ is a map, let $\Gamma \backslash x$ indicate the map which is identical to $\Gamma$ but contains no binding for $x$.
\\

\noindent Definition: Let $e[v/x]$ be the standard capture-avoiding substitution relation. It differs from the effect one in that it operates on expressions/values/variables instead of effects and effect variables. We also define it to be the identity function if $e$ is a value.
\\

\noindent Theorem: If $\Gamma[x] = \tau$, $v : \tau$, and $\Gamma, \epsilon \vdash e\ \colon \tau, \epsilon'$, then $\Gamma\backslash x, \epsilon \vdash e[v/x]\ \colon \tau, \epsilon'$

\noindent Proof: Structural induction on first typing proof. The interesting cases are:

\begin{itemize}
	\item In the VAR case $e = z$, either $z = x$ in which case $e[v/x] = v$ and the premise $v : \tau$ solves it, or $z <> x$ in which case $z \in \Gamma\backslash x$ and we simply use the VAR rule.
	\item In the LET case $e = \texttt{let } z = e_1 \texttt{ in }e_2$ either $z = x$ in which case $\Gamma\backslash z[x := \tau_1] = \Gamma[x := \tau_1]$ and we do not substitute in $e_2$, or $z <> x$ in which case $\Gamma\backslash z[x := \tau_1] = \Gamma[x := \tau_1]\backslash z$ and we do substitute in $e_2$. In either case the result follows immediately.
	\item Similar reasoning works for the ABS case.
	\item The subtyping case is immediate, but it bears noting that we don't change any of the types or effects that appear in the original derivation.
\end{itemize}

\clearpage
\section*{Operational Semantics}

Now we'll define an operational semantics for our language. We are modeling a situation in which global variables are ordered in a pipeline, such that each global variable must be accessed after the ones before it in the pipeline.

Our big-step operational semantics relation will have the form $(\Gamma, G, n, e) \Rightarrow (G', n', e')$, where $\Gamma$ is an environment mapping variables to values, $G$ is an array $[v_1; \dots; v_n]$ of the current values for each global variable, $n$ is an integer indicating the current pipeline stage, and $e$ is an expression to be evaluated. We treat $G$ as a map from integers to values, so $G[1] = v_1$, etc. We say $G$ is well-typed if $G[i] : T_i$ for $1 \leq i \leq n$.

As usual, the metavariable $v$ will refer exclusively to values, while $e$ represents any expression. We use $\oplus$ to denote regular integer addition.

\subsection*{Big-step}

\begin{mathpar}
	\relationRule{value}{
		\\
	}{
		(\Gamma, G, n, v) \Rightarrow (G, n, v)
	}
	
	\relationRule{variable}{
		\Gamma[x] = v
	}{
		(\Gamma, G, n, x) \Rightarrow (G, n, v)
	}

	\relationRule{sum}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, i_1)\\
		(\Gamma, G_1, n_1, e_2) \Rightarrow (G_2, n_2, i_2)\\
		i_1, i_2 \in \Z
	}{
		(\Gamma, G, n, (e_1, e_2)) \Rightarrow (G_2, n_2, i_1 \oplus i_2)
	}

	\relationRule{pair}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, v_1)\\
		(\Gamma, G_1, n_1, e_2) \Rightarrow (G_2, n_2, v_2)
	}{
		(\Gamma, G, n, (e_1, e_2)) \Rightarrow (G_2, n_2, (v_1, v_2))
	}
	
	\relationRule{fst}{
		(\Gamma, G, n, e) \Rightarrow (G_1, n_1, (v_1, v_2))
	}{
		(\Gamma, G, n, \texttt{fst } e) \Rightarrow (G_1, n_1, v_1)
	}

	\relationRule{snd}{
		(\Gamma, G, n, e) \Rightarrow (G_1, n_1, (v_1, v_2))
	}{
		(\Gamma, G, n, \texttt{snd } e) \Rightarrow (G_1, n_1, v_2)
	}
	
	\relationRule{let}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, v_1)\\
		(\Gamma[x := v_1], G_1, n_1, e_2) \Rightarrow (G_2, n_2, v_2)\\
	}{
		(\Gamma, G, n, \texttt{let } x = e_1 \texttt{ in } e_2) \Rightarrow (G_2, n_2, v_2)
	}

	\relationRule{if-true}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, \texttt{True})\\
		(\Gamma, G_1, n_1, e_2) \Rightarrow (G_2, n_2, v)\\
	}{
		(\Gamma, G, n, \texttt{if } e_1 \texttt{ then } e_2 \texttt{ else } e_3) \Rightarrow (G_1, n_2, v)
	}

	\relationRule{if-false}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, \texttt{False})\\
		(\Gamma, G_1, n_1, e_3) \Rightarrow (G_2, n_2, v)\\
	}{
		(\Gamma, G, n, \texttt{if } e_1 \texttt{ then } e_2 \texttt{ else } e_3) \Rightarrow (G_1, n_2, v)
	}
	
	\relationRule{deref}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, g_i)\\
		n_1 <= i
	}{
		(\Gamma, G, n, !e) \Rightarrow (G_1, i+1, G_1[i])
	}

	\relationRule{update}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, v_1)\\
		(\Gamma, G_1, n_1, e_2) \Rightarrow (G_2, n_2, g_i)\\
		n_2 <= i
	}{
		(\Gamma, G, n, e_2 := e_1) \Rightarrow (G_2[i := v_1], i+1, ())
	}

	\relationRule{abs}{
		\
	}{
		(\Gamma, G, n, \texttt{fun } [\alpha]\ (x : \tau, \epsilon) \rightarrow e) \Rightarrow (G, n, < \Gamma, \alpha, (x : \tau, \epsilon), e>)
	}

	\relationRule{app}{
		(\Gamma, G, n, e_1) \Rightarrow (G_1, n_1, < \Gamma', \alpha, (x : \tau, \epsilon), e>)\\
		(\Gamma, G_1, n_1, e_2) \Rightarrow (G_2, n_2, v_2)\\
		(\Gamma'[x := v_2], G_2, n_2, e) \Rightarrow (G_3, n_3, v_3)\\
	}{
		(\Gamma, G, n, e_1\ e_2) \Rightarrow (G_3, n_3, v_3)
	}
\end{mathpar}

\subsection*{Big-step weakening}

During our soundness proof, we will need to use the following theorem, which states that if a program evaluates from a state then it also evaluates from every earlier state.
\\

\noindent Theorem: If $(\Gamma, G, n, e) \Rightarrow (G', n', v)$ and $m \leq n$ then $(\Gamma, G, m, e) \Rightarrow (G', m', v)$ for some $m' \leq n'$.
\\

\noindent Proof: Straightforward induction on the proof of evaluation. The only mildly interesting cases are DEREF and UPDATE, where we use transitivity of $\leq$ and the fact that $i+1 \leq i+1$.

\subsection*{Big-step soundness}

Since our language (and also dpt!) doesn't allow recursion or looping, we can show not only that well-typed programs do not get stuck, but that they terminate (i.e. well-typed programs are normalizing).
\\

\newcommand{\okvalue}{good}
\noindent Definition: A value is \emph{\okvalue} if whenever $v : \forall \alpha.(\tau_{in}, \epsilon_{in}) \rightarrow (\tau_{out}, \epsilon_{out})$, we know that $v =\ <\Gamma, \alpha, (x : \tau_{in}, \epsilon_{in}), e>$ and for all $G, i, v_x$ where $G$ is well-typed and $v_x : \tau_{in}[i/\alpha]$, $(\Gamma_\tau[x := v_x], G, \epsilon[i/\alpha], e) \Rightarrow (G', i', v)$ where $G'$ is well-typed, $i' \leq \epsilon_{out}[i/\alpha]$, and $v : \tau_{out}[i/\alpha]$ and $v$ is \okvalue.
\\

\noindent Definition: for all typing environments $\Gamma$, let $\Gamma_v$ denote any evaluation environment such that for all $x \in \Gamma$, $\Gamma_v[x] = v_x$ where $v_x : \Gamma[x]$ and $v_x$ is \okvalue.
\\

\noindent Desired Theorem: \\\indent If $\emptyset, 1 \vdash e\ \colon \tau, n+1 $ then for all $G$ there exist some $G', n', v$ such that $(\emptyset, G, 1, e) \Rightarrow (G', n', v)$
\\

\noindent Unfortunately this won't give us a useful induction hypothesis, so we must prove a generalization instead:
\\

\noindent Generalized Theorem: \\\indent If $\Gamma, i \vdash e\ \colon \tau, j$ then for all well-typed $G$ there exist some $G', i', v$ such that $v$ is \okvalue, $v : \tau$, $i' \leq i$, $G'$ is well-typed, and $(\Gamma_v, G, i, e) \Rightarrow (G', i', v)$.
\\

\noindent Fortunately it is immediately obvious that the general theorem implies the desired one. For now we'll prove it assuming there's no polymorphism; that is, no effects anywhere in the program or judgements include any type variables. To prove it with polymorphism, we would probably have to instantiate any type variables in the judgement and do so in a consistent way, and then say that $e$ evaluates for all such instantiations. 

Roughly, something like "Let $[\alpha_1, \dots, \alpha_k]$ be the set of type variables appearing inside $e$. For any set of integer effects $\mathbb{I} = \{i_1, \dots i_k\}$, let $e_\mathbb{I}$ denote $e[i_1/\alpha_1]...[i_k/\alpha_k]$, and similarly for other things. Then if $\Gamma_\mathbb{I}, (\epsilon_1)_\mathbb{I} \vdash e_\mathbb{I} : \tau_\mathbb{I}, (\epsilon_2)_\mathbb{I}$ then $(\Gamma_v, G, (\epsilon_1)_\mathbb{I}, e_\mathbb{I}) \Rightarrow (G', i', v)$ where $i' \leq (\epsilon_2)_\mathbb{I}$, and $v : \tau_\mathbb{I}$ and $G'$ is well-typed and $v$ is \okvalue.
\\

\noindent Proof of Generalized Theorem: Induction on the proof that $\Gamma, i \vdash e\ \colon \tau, j$.
\\

Case $\texttt{Int/True/False/Global Variable}$. In these cases, $e$ is a value, so we may apply the value rule to show that $(\Gamma_v, G, i, e) \Rightarrow (G, i, v)$, and we can show $v : \tau$ using the appropriate rule appearing in the title of the case. Note that we won't need to use subtyping when we do so.
\\

Case $\texttt{Local Variable}$. Our premise gives us that $\Gamma[x] = \tau$. Hence by definition, $\Gamma_v[x] = v_x$, $v_x : \tau$, and $v_x$ is \okvalue. Thus we may use the \texttt{Variable} rule to show that $(\Gamma_v, G, i, e) \Rightarrow (G, i, v_x)$.
\\

Case $\texttt{Pair}$. 
From our premise:
\begin{itemize}
	\item $e = e_1\ e_2$
	\item $\Gamma, i \vdash e_1\ \colon \tau_1, \epsilon_1$
	\item $\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2, j$
	\item IH1: $(\Gamma_v, G, i, e_1) \Rightarrow (G_1, i_1, v_1) \wedge i_1 \leq \epsilon_1 \wedge v_1 : \tau_1 \wedge G_1 \mbox{ is well-typed}$
	\item IH2: $(\Gamma_v, G_1, \epsilon_1, e_2) \Rightarrow (G_2, i_2, v_2) \wedge i_2 \leq \epsilon_2 \wedge v_2 : \tau_2 \wedge G_2 \mbox{ is well-typed}$
\end{itemize}

This is almost enough to apply the PAIR evaluation rule, but unfortunately that rule requires the output of the first to match the input of the second. Fortunately since we know that $i_1 \leq \epsilon_1$, we may use weakening to show that $(\Gamma_v, G_1, i_1, e_2) \Rightarrow (G_2, i_2', v_2)$ for some $i_2' \leq i_2$, and now we may use the PAIR rule to conclude that $(\Gamma_v, G, i, e_1) \Rightarrow (G_2, i_2', (v_1, v_2))$. Next, we note that $i_2' \leq i_2 \leq \epsilon_2$, and that $(v_1, v_2) : \tau_1 * \tau_2$ can be easily shown using the PAIR typing rule plus the fact that $v_1 : \tau_1$ and $v_2 : \tau_2$. Finally, note that $G_2$ being well typed is part of IH2, since $G_1$ is well-typed.
\\

Case PLUS: Same as the PAIR case, but we also need to use our canonical forms lemma to satisfy the prerequisite of SUM that both values be integers.
\\

Case FST: $e = \texttt{fst } e_1$. We know that $\Gamma, i \vdash e_1\ \colon \tau_1 * \tau_2, \epsilon_1$, so by induction $(\Gamma_v, G, i, e) \Rightarrow (G', i', v)$, where $v : \tau_1 * \tau_2$, $i' \leq i$, and $G'$ is well-typed. Our canonical forms lemma lets us conclude that $v = (v_1, v_2)$ and $v_1 : \tau_1$, so we may apply the FST rule to show that $(\Gamma_v, G, i, \texttt{fst } e) \Rightarrow (G', i', v_1)$. That was all that remained to be shown.
\\

Case SND: Analogous to FST.
\\

Case LET: $e = \texttt{let } x = e_1 \texttt{ in } e_2$. We know that $\Gamma, i \vdash e_1\ \colon \tau_1, \epsilon_1$ and $\Gamma[x := \tau_1], \epsilon_1 \vdash e_2\ \colon \tau_2, \epsilon_2$. Thus by induction we get
$$(\Gamma_v, G, i, e_1) \Rightarrow (G_1, i_1, v_1)\mbox{ and }(\Gamma[x := \tau_1]_v, G_1, \epsilon_1, e_2) \Rightarrow (G_2, i_2, v_2),$$
where $i_1 \leq \epsilon_1$, $i_2 \leq \epsilon_2$, $v_1 : \tau_1$ and $v_2 : \tau_2$. We note that by induction, $v_1$ is \oktype, and since $v_1 : \tau_1$ and $\tau_1 = \Gamma[x := \tau_1][x]$, $\Gamma_v[x := v_1]$ is a valid instance of $\Gamma[x := \tau_1]_v$. We also apply weakening to our second hypothesis as in the PAIR case so that it begins evaluation at $i_1$ instead of $\epsilon_1$. This gives us everything we need to apply the LET rule and show that $(\Gamma_v, G, i, e) \Rightarrow (G_2, i_2, v_2)$.
\\

Case IF: By induction we know that $e$ evaluates to a value $v$ and $v : \texttt{Bool}$, and hence by canonical forms $v = \texttt{True}$ or $v = \texttt{False}$. We can then apply weakening to the other hypotheses and then use IF-TRUE or IF-FALSE as appropriate.
\\

Case DEREF: We know that
\begin{itemize}
	\item DEREF: $\Gamma, i \vdash e\ \colon \tau, \epsilon_1+1$
	\item INV1: $e = !e_1$
	\item INV2: $\Gamma, i \vdash e_1\ \colon \texttt{ref}(\tau, \epsilon_1), \epsilon_1$
	\item IH: $(\Gamma_v, G, i, e_1) \Rightarrow (G', i', v) \wedge i' \leq \epsilon_1 \wedge v : \texttt{ref}(\tau, \epsilon_1) \wedge G' \mbox{ is well-typed}$.
\end{itemize}

By canonical forms, we conclude that $\tau = T_j$ and $v = g_j$ where $\epsilon_1 = j \in \Z$. Hence $i' \leq \epsilon_1 = j$, so we may apply the DEREF rule to show that $(\Gamma_v, G, i, !e_1) \Rightarrow (G_1, j+1, G_1[j])$. Then by reflexivity $j + 1 \leq \epsilon_1 + 1$, and since $G$ is well-typed $G_1$ is as well. Thus $G_1[j] : T_j = \tau$, which was all that remained to show.
\\

Case UPDATE: We know that
\begin{itemize}
	\item UPDATE: $\Gamma, i \vdash e_2 := e_1\ \colon \texttt{Unit}, \epsilon_2 + 1$
	\item INV1: $e = e_2 := e_1$
	\item INV2: $\Gamma, i \vdash e_1\ \colon \tau, \epsilon_1$
	\item INV3: $\Gamma, \epsilon_1 \vdash e_2\ \colon \texttt{ref }(\tau, \epsilon_2), \epsilon_2$
	\item IH1: $(\Gamma_v, G, i, e_1) \Rightarrow (G_1, i_1, v_1) \wedge i_1 \leq \epsilon_1 \wedge v_1 : \tau \wedge G_1 \mbox{ is well-typed}$.
	\item IH2: $(\Gamma_v, G_1, \epsilon_1, e_2) \Rightarrow (G_2, i_2, v_2) \wedge i_2 \leq \epsilon_2 \wedge v_2 : \texttt{ref}(\tau, \epsilon_2) \wedge G_2 \mbox{ is well-typed}$.
\end{itemize}
We immediately apply weakening to IH2 so that its input is $i_1$ instead of $\epsilon_1$. By canonical forms, $\tau = T_j$ and $v_2 = g_j$ where $\epsilon_2 = j \in \Z$. Thus since $i_2 \leq \epsilon_2 = j$, we may use the UPDATE rule to show that $(\Gamma_v, G, i, e_2 := e_1) \Rightarrow (G_2[j := v_1], j+1, ())$. It's immediate that $j+1 \leq \epsilon_2+1$ (by reflexivity) and that $() : \texttt{Unit}$. Last, we know that $G_2$ is well-typed and $v_1 : \tau = T_j$, so $G_2[j := v_1]$ is well-typed as well.
\\

Case ABS: We know that 
\begin{itemize}
	\item INV1: $e = \texttt{fun } [\alpha]\ (x : \tau_{in}, \epsilon_{in}) \rightarrow e_{body}$
	\item ABS: $\Gamma, \epsilon \vdash e\ \colon \forall \alpha.(\tau_{in}, \epsilon_{in}) \rightarrow (\tau_{out}, \epsilon_{out})$
	\item INV2: $\Gamma[x := \tau], \epsilon_{in} \vdash e_{body}\ \colon \tau_{out}, \epsilon_{out}$
	\item IH1: $(\Gamma[x := \tau]_\tau, G, \epsilon_{in}, e_{body}) \Rightarrow (G', i', v) \wedge i' \leq \epsilon_{out} \wedge v : \tau_{out} \wedge v \mbox{ is \okvalue}$
\end{itemize}
For now, let's ignore polymorphism (So, in particular, all $\epsilon$s are integers, and substitution is a no-op).

We may immediate apply the ABS rule to show that if $v_{out} =\ <\Gamma_v, \alpha, (x : \tau_{in}, \epsilon_{in}), e_{body})>$ then
$(\Gamma_v, G, i, e) \Rightarrow (G, i, v)$. We can then use the CLOSURE rule to show that $v : \forall \alpha.(\tau_{in}, \epsilon_{in}) \rightarrow (\tau_{out}, \epsilon_{out})$, and of course $G$ is well-typed and $i \leq i$. So we need only show that $v$ is \okvalue. 

First, $v$ is in fact a closure. Since substitution is a no-op, we need only show that $(\Gamma_v[x := v_x], G, \epsilon_{in}, e_{body}) \Rightarrow (G', i', v')$ plus all the other stuff, which falls out immediately from INV2 by induction. (Ok we also have to do the reasoning from the LET case involving $\Gamma_v$)
\\

Case APP: We know that
\begin{itemize}
	\item APP: $\Gamma, i \vdash e_1[\epsilon_\alpha] e_2\ \colon \tau'[\epsilon_\alpha/\alpha], \epsilon'[\epsilon_\alpha/\alpha]$
	\item INV1: $e = e_1[\epsilon_\alpha] e_2$
	\item INV2: $\Gamma, i \vdash e_1\ \colon \forall\alpha.(\tau_2, \epsilon_2) \rightarrow (\tau', \epsilon'), \epsilon_1$
	\item INV3: $\Gamma, \epsilon_1 \vdash e_2\ \colon \tau_2[\epsilon_\alpha/\alpha], \epsilon_2[\epsilon_\alpha/\alpha]$
	\item IH1: $(\Gamma_v, G, i, e_1) \Rightarrow (G_1, i_1, v_1) \wedge i_1 \leq \epsilon_1 \wedge v_1 : \forall\alpha.(\tau_2, \epsilon_2) \rightarrow (\tau', \epsilon') \wedge G_1 \mbox{ is well-typed}$.
	\item IH2: $(\Gamma_v, G_1, \epsilon_1, e_2) \Rightarrow (G_2, i_2, v_2) \wedge i_2 \leq \epsilon_2 \wedge v_2 : \tau_2[\epsilon_\alpha/\alpha], \epsilon_2[\epsilon_\alpha/\alpha] \wedge G_2 \mbox{ is well-typed}$.
	\item \okvalue: $v_1 =\ <\Gamma_v', \alpha, (x : \tau_2, \epsilon_2), e_{body}>$ and $(\Gamma_v'[x := v_2], G_2, \epsilon_{\tau_2}, e_{body}) \Rightarrow (G_3, i_3, v)$ where $G_3$ is well-typed, $i_3 \leq \epsilon'[i/\alpha]$, $v : \tau'[i/\alpha]$ and $v$ is \okvalue.
\end{itemize}
By applying weakening twice, we can use IH1 to fulfill the first premise of APP, IH2 for the second, and the evaluation part of "\okvalue" finishes it off.
\\

Case SUBTYPING: 
By induction, $(\Gamma_v, G, i, e) \Rightarrow (G', i', v)$ where $G'$ is well-typed, $i' \leq \epsilon_1 \leq \epsilon_2$, $v : \tau_1$, and $v$ is \okvalue. The only thing to show is that $v : \tau_2$, which can be done with a single application of the SUBTYPING rule since we know that $\tau_1 <: \tau_2$.







\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End: 
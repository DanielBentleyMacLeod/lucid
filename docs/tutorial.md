# Tutorial 1: Introduction to Lucid

This tutorial introduces the core features of Lucid and walk through the process of running a program on the Lucid interpreter. 

## Core Lucid abstractions
There are three core abstractions in Lucid: events, handlers, and arrays. To see how we use these primitives, lets look at ``examples/histogram.dpt`` -- a simple measurement application that reports a histogram of recent packet sizes to a collection server at regular intervals. 

Here's a visual representation of ``histogram.dpt``:

![histogram_monitor](histogram.jpg)

### Events and Handlers

When ip packets arrive, the switch generates an ``ip_in`` *event*. This event is declared in the Lucid program and carries the packet's addresses, input port, ip length, and ip tos. The ``ip_in`` *handler* processes the event. The handler:

1. Increments a histogram array that persists across packets.
2. Increments a total packet count array.
3. Sends the packet back out of its input port.
4. If the total packet count is above a threshold, generates a ``report`` event to export the histogram to the collection server and reset it. 

Here's the handler code: 

```
handle ip_in (int<<9>> igr_port, int src, int dst, int<<16>> len, int<<8>> tos) {
  int idx = 0;
  if (len <= 128) { 
    idx = 0;
  } else {
    if (len <= 512) {
      idx = 1;
    } else {
      if (len <= 1024){ 
        idx = 2;
      } else {
        idx = 3;
      }
    }
  }
  Array.setm(hist_arr, idx, incr, 1);
  int total_ct = Array.update(total_arr, 0, incr, 1, incr, 1);
  if (total_ct == pktct_interval) {
    generate report(0);
  }
  generate ip_out(igr_port, src, dst);
}
```

As we can see in this ``ip_in`` handler, handlers are simple imperative functions that can generate other events. When a handler generates an event, the event is encoded into a packet, recirculated, and processed in a subsequent pass through the switch's pipeline. You can think of a handler ``foo`` that generates an event ``bar`` as a function ``foo`` that invokes a continuation or callback function ``bar`` asynchronously, at some time in the future. Handlers that generate events are powerful because they express recursive computation in a way that maps naturally to the underlying hardware. In the histogram example, the ``report`` event is recursive: 
```
handle report(int idx){
    int cur_idx = idx; 
    int column_ct = Array.update(hist_arr, cur_idx, getf, 0, setf, 0);
    generate ip_out(collector_port, cur_idx, column_ct);                
    if (cur_idx == 0) {
      Array.set(total_arr, 0, 0);      
    }
    if (cur_idx < 3){       
      generate report(cur_idx + 1);
    }
}
```

This handler processes ``hist_arr[idx]``, then generate another ``report`` event to process ``hist_arr[idx+1]``. Each event gets executed in a separate pass through the switch's pipeline and the recursion continues until all 4 elements of ``hist_arr`` are processed. Each recursive call has a cost -- a packet is recirculated. But there is no way around that, since the underlying hardware can only access one element of each persistent memory array per packet. 

#### Entry and exit events

In ``histogram.dpt``, we see that some event declarations are prefixed with the ``entry`` or ``exit`` keyword. 
```
entry event ip_in (int<<9>> igr_port, int src, int dst, int<<16>> len, int<<8>> tos);
event report(int idx);
exit event ip_out (int<<9>> egr_port, int src, int dst);
```

A regular event, without either keyword, is an event that is generated by a Lucid handler and processed by a Lucid handler. Entry and exits events are how a switch transfers control flow to / from a Lucid program. An *entry* event is an event that is generated by *the switch's underlying P4 program* and processed by a Lucid handler. Finally, an *exit* event is the opposite of an entry event -- it is generated by a Lucid handler and *processed by the underlying P4 program*. We will talk about this more in a later tutorial that goes over compiling Lucid programs to P4. 


### Arrays 

Lucid programs interact with persistent state with the *Array* module, which is used in the above snippet. When you call a method of the Array module, you typically pass it a memop function -- a simple function that describes the computation to perform on state read from persistent memory before returning the result to either the memory cell it was read from, or a local variable in the handler. For example, in ``ip_in``, we see this line: ``Array.setm(hist_arr, idx, incr, 1);``, which we would write in C as: ``hist_arr[idx] = incr(hist_arr[idx], 1);`` The point of writing this line as a call to Array.setm, instead of some general syntax like C, is to ensure that the program only does a small amount of computation between the read and the write to ``hist_arr[idx]``, so that Lucid can guarantee that is will compile to the underlying hardware. 

Lucid ensures that Array operations are simple enough for the hardware by placing syntactic restrictions on the functions that can be passed to array methods -- ``incr``, for example. These restricted functions are "memops" -- operations that are simple enough to perform on persistent memory at line rate. Memops are just functions that must adhere to three simple rules:

1. a memop can only have two arguments.
2. a memop can only consist of a return statement, or a single if / else statement with a return statement in each branch.
3. a memop can only use each of its arguments once in its body. 

If a function does not adhere to these rules, a Lucid program will not type check and the Lucid type checker will tell the programmer which rule failed for which memop. These restrictions are *more* limiting than the restrictions of the underlying hardware, but they present a simpler and regular interface to state that simplifies a developer's mental model. In the future, our goal is for Lucid's memop syntax to be extendible, so that developers can choose their own balance between regularity and completeness. 

In ``ip_in`` from ``histogram.dpt``, the ``incr`` memop is also passed to ``Array.update``, which performs memory read and write operations in parallel. In the example, we have ``int total_ct = Array.update(total_arr, 0, incr, 1, incr, 1);``. In C, we would write this as: ``int tmp = incr(total_arr[0], 1); total_arr[0] = incr(total_arr[0], 1); total_ct = tmp;``. 

Again, Lucid can guarantee that any ``Array.update`` call can be compiled to the underlying hardware, because of the restrictions on memops. 

A second restriction on arrays is that, in every handler, all arrays must be accessed in the order that they are declared. This is also enforced by the type checker, to catch programs that have no chance of compiling to the underlying hardware and give programmers useful error messages when they write such programs. 


## The Lucid interpreter

Why use the Lucid interpreter instead of compiling to P4-Tofino and testing on the Tofino ASIC model? 

1. **Agile development** Compiling to P4, then to Tofino, then running the ASIC model takes a long time -- 30+ seconds for a simple program, possibly hours for a complex program. The interpreter, on the other hand, runs almost instantly (unless you are simulating a large workload). This makes iterating and prototyping *much* faster than in P4, where your only option is to compile everything to the ASIC model.

2. **Semantics and compiler bugs** The interpreter defines the semantics of the Lucid language in a relatively straightforward way. It is relatively free of bugs, because it is so much less complex than the Lucid --> Tofino toolchain. Simply put, in the interpreter things work the way they are supposed to work. So, you can use the interpreter to quickly gain confidence that there are no logical bugs in your program. In P4, its often very hard to tell if a program doesn't work because of a logical bug, a compiler bug, or a misunderstanding of the underlying hardware. 

3. **Language features** The interpreter supports the full Lucid language. There are some features not yet supported by the compiler, such as delaying events and scheduling events to execute at different nodes in the network. 

4. **Type-and-effects checking** The final reason to use the interpreter is because Lucid's type checking is done before interpretation. So, if your Lucid program that interprets, you *know* that the program uses persistent state in a way that can be mapped to the underlying hardware. That being said, it is still possible to write programs that interpret, but cannot fit into the underlying hardware's resources. Typically we use the interpreter for fast prototyping and correctness testing, then switch to the compiler when it is time to optimize the program. 


## Using the interpreter
Let's run the interpreter on the histogram example program. Assuming you compiled Lucid successfully, cd to the ``<git root>/examples/tutorial`` directory and run ``../../dpt histogram.dpt --spec histogram.json``. You should see output like this: 

```
vagrant@lucidvm:/lucid/examples/tutorial$ ../../dpt histogram.dpt --spec histogram.json
dpt: Parsing ...
Processing histogram.dpt
#
# many elided lines of output here
#
dpt: Done
```

There are two things to understand about the interpreter: its input and output. 

### Interpreter input specification
The interpreter type checks a program and then executes it on a pre-defined trace of events that we specify in a json file. For the histogram example, the specification file is ``examples/tutorial/histogram.json``, which looks like: 

```
{
  "switches": 1,
  "max time": 9999999,
  "default input gap": 10000,
  "random seed": 0,
  "events": [
    {"name":"ip_in", "args": [128, 1, 2, 256, 0]},
    {"name":"ip_in", "args": [128, 2, 2, 256, 0]},
    {"name":"ip_in", "args": [128, 3, 2, 256, 0]},
    {"name":"ip_in", "args": [128, 4, 2, 768, 0]},
    {"name":"ip_in", "args": [128, 5, 2, 768, 0]}
  ]
}
```

In this specification file: 
- ``switches`` is the number of nodes in the model network. All nodes are directly connected. 
- ``max time`` is the number of time units to run the simulation for. Simulation time is in nanoseconds.
- ``default input gap`` is the number of nanoseconds between events provided to the simulator.
- ``random seed`` is used internally by the interpreter for hash functions and anything else that requires randomness. 
- ``events`` are the events that the interpreter executes the program on. Each event object has a ``name``, literally the name of the event, and ``args``, which are an order list of arguments to the event. So, for example, the line ``{"name":"ip_in", "args": [128, 1, 2, 256, 0]}`` will generate the same event as the Lucid statement ``generate ip_in(128, 1, 2, 256, 0);``. 
- ``timestamp and locations`` (not shown in the example) each event can also have a timestamp (in nanoseconds from simulation start time) and a location, which defines exactly when and where the event executes. So for example, if we had a network with two switches, we could schedule two concurrent ``ip_in`` events at them with the lines: 
```
{"name":"ip_in", "args": [128, 1, 2, 256, 0], "timestamp" : 10000, "locations" : [0]},
{"name":"ip_in", "args": [128, 2, 2, 256, 0], "timestamp" : 10000, "locations" : [1]}
```

### Interpreter output

When you run the interpreter, you get messages from Lucid's type checker, then a trace of the execution of the program on the input trace. Here's the simulation output that we get from the histogram example: 

```
vagrant@lucidvm:/lucid/examples/tutorial$ ../../dpt histogram.dpt --spec histogram.json
dpt: Parsing ...
Processing histogram.dpt
#
# type checking messages elided
# 
dpt: Simulating...
dpt: Using random seed: 0

t=0: Handling entry event ip_in(128,1,2,256,0) at switch 0
t=10000: Handling entry event ip_in(128,2,2,256,0) at switch 0
t=20000: Handling entry event ip_in(128,3,2,256,0) at switch 0
t=30000: Handling entry event ip_in(128,4,2,768,0) at switch 0
t=30600: Handling event report(0) at switch 0
t=31200: Handling event report(1) at switch 0
t=31800: Handling event report(2) at switch 0
t=32400: Handling event report(3) at switch 0
t=40000: Handling entry event ip_in(128,5,2,768,0) at switch 0
dpt: Final State:

Switch 0 : {

 Pipeline : [
    0 : [0u32; 0u32; 1u32; 0u32]
    1 : [1u32]
  ]

 Events :   [ ]

 Exits :    [
    ip_out(128,1,2) at t=0
    ip_out(128,2,2) at t=10000
    ip_out(128,3,2) at t=20000
    ip_out(128,4,2) at t=30000
    ip_out(132,0,0) at t=30600
    ip_out(132,1,3) at t=31200
    ip_out(132,2,1) at t=31800
    ip_out(132,3,0) at t=32400
    ip_out(128,5,2) at t=40000
  ]

 entry events handled: 5
 total events handled: 9

}
dpt: Done
```

The first part of the simulator output is a time-ordered trace of the events that the Lucid program handled, e.g., ``t=0: Handling entry event ip_in(128,1,2,256,0) at switch 0``. The interpreter also supports printf functions that can print messages in this trace -- useful for debugging. 

The second part of the simulator output is the final state of each simulated switch. The final state of a switch has three parts: 
1. ``Pipeline`` -- this is a list of the state of all persistent arrays in the program. For now, the simulator tells you the ID of the array, rather than its name. The first array declared in the program gets ID 0, the second array declared gets ID 1, and so on. So, in the above trace, the line ``0 : [0u32; 0u32; 1u32; 0u32]`` tells us that the array declared first in the program, i.e., ``global Array.t<<32>> hist_arr = Array.create(4);``, ended execution with zeros in all cells except at index 2, which had value 1.

2. ``Events`` -- this is a list of events that were still pending at the switch when the simulation ended. This will often be empty. 

3. ``Exits`` -- this is a list of exit events that the switch generated throughout its execution. Note that generation of non-exit events are not shown in this list. For example, the ``report`` events that the ``histogram.dpt`` program generates are not shown -- only the ``ip_out`` events. 

Finally, at the end of the switch state block is a summary of the number of events and entry events handled by the switch. 


## Compiling to P4


### An IP harness file

### Compiling to P4

### Compiling to the Tofino

### Testing with the Tofino-model

### Automation
